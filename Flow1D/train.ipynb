{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import utils\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from Flow1D import Flow1D\n",
    "from dataset import GaussianMixtureDataset\n",
    "\n",
    "from util.plot import plot_results_flow_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating the synthetic dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distribution:\n",
    "means = torch.tensor([-1, 3], dtype=torch.float32)\n",
    "standard_deviations = torch.tensor([0.5, 1], dtype=torch.float32)\n",
    "mix_coefs = torch.tensor([0.5, 0.5])\n",
    "\n",
    "# Generating the dataset\n",
    "dataset = GaussianMixtureDataset(mix_coefs, means, standard_deviations, num_samples=1024)\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a model**\n",
    "Model transforms the data distribution (unknown) to Beta(2, 2) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "alpha = 2\n",
    "beta = 2\n",
    "model = Flow1D(num_mixture_components=5, alpha=alpha, beta=beta).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing model's performance before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data gymnastics\n",
    "data = dataset.data.to(device)\n",
    "transformed_data = model(dataset.data.to(device))\n",
    "plot_results_flow_1D(data, transformed_data, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    avg_loss = []\n",
    "    for batch_idx, data_points in enumerate(data_loader):\n",
    "        # Data gymnastics\n",
    "        data_points = data_points.to(device)\n",
    "\n",
    "        # Loss\n",
    "        loss = model.get_loss(data_points)\n",
    "        avg_loss.append(loss.item())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Making an update\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = torch.mean(torch.tensor(avg_loss))\n",
    "    print('Epoch %d\\t Loss=%.5f' % (epoch, avg_loss))\n",
    "    losses.append(avg_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
